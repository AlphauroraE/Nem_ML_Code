{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Experiments on the Child Opportunity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f9943dd7e645>:6: DtypeWarning: Columns (14,23,32,41,50,59,68,77,86,95,104,113,122,131) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"2_subdomains.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Import these libraries for data processing (pandas version 2.0.0)\n",
    "# and changing directories (os)\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Change directory into whichever one holds the csv file\n",
    "# os.chdir(\"/Users/Qidi/Downloads/Qidi's School Notes!/School/SD1/2_subdomains\")\n",
    "\n",
    "# df stands for \"dataframe\". This is your bread and butter for machine learning.\n",
    "# Use pandas to read that csv into the df variable.\n",
    "df = pd.read_csv(\"2_subdomains.csv\")\n",
    "\n",
    "# It took me 14.8 seconds to load this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid10</th>\n",
       "      <th>year</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>state_usps</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>county_name</th>\n",
       "      <th>metro_fips</th>\n",
       "      <th>metro_name</th>\n",
       "      <th>metro_type</th>\n",
       "      <th>...</th>\n",
       "      <th>z_SE_SR_met</th>\n",
       "      <th>c5_SE_WL_nat</th>\n",
       "      <th>c5_SE_WL_stt</th>\n",
       "      <th>c5_SE_WL_met</th>\n",
       "      <th>r_SE_WL_nat</th>\n",
       "      <th>r_SE_WL_stt</th>\n",
       "      <th>r_SE_WL_met</th>\n",
       "      <th>z_SE_WL_nat</th>\n",
       "      <th>z_SE_WL_stt</th>\n",
       "      <th>z_SE_WL_met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>33860.0</td>\n",
       "      <td>Montgomery, AL</td>\n",
       "      <td>Metropolitan Statistical Area</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.185168</td>\n",
       "      <td>0.046977</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>33860.0</td>\n",
       "      <td>Montgomery, AL</td>\n",
       "      <td>Metropolitan Statistical Area</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.241784</td>\n",
       "      <td>-0.050226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>33860.0</td>\n",
       "      <td>Montgomery, AL</td>\n",
       "      <td>Metropolitan Statistical Area</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.329964</td>\n",
       "      <td>-0.160692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>33860.0</td>\n",
       "      <td>Montgomery, AL</td>\n",
       "      <td>Metropolitan Statistical Area</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.179954</td>\n",
       "      <td>0.145209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>33860.0</td>\n",
       "      <td>Montgomery, AL</td>\n",
       "      <td>Metropolitan Statistical Area</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.150777</td>\n",
       "      <td>0.187417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      geoid10  year  state_fips state_usps state_name  county_fips   \n",
       "0  1001020100  2012           1         AL    Alabama         1001  \\\n",
       "1  1001020100  2013           1         AL    Alabama         1001   \n",
       "2  1001020100  2014           1         AL    Alabama         1001   \n",
       "3  1001020100  2015           1         AL    Alabama         1001   \n",
       "4  1001020100  2016           1         AL    Alabama         1001   \n",
       "\n",
       "               county_name  metro_fips      metro_name   \n",
       "0  Autauga County, Alabama     33860.0  Montgomery, AL  \\\n",
       "1  Autauga County, Alabama     33860.0  Montgomery, AL   \n",
       "2  Autauga County, Alabama     33860.0  Montgomery, AL   \n",
       "3  Autauga County, Alabama     33860.0  Montgomery, AL   \n",
       "4  Autauga County, Alabama     33860.0  Montgomery, AL   \n",
       "\n",
       "                      metro_type  ...  z_SE_SR_met  c5_SE_WL_nat c5_SE_WL_stt   \n",
       "0  Metropolitan Statistical Area  ...          NaN      Moderate     Moderate  \\\n",
       "1  Metropolitan Statistical Area  ...          NaN           Low     Moderate   \n",
       "2  Metropolitan Statistical Area  ...          NaN           Low     Moderate   \n",
       "3  Metropolitan Statistical Area  ...          NaN      Moderate         High   \n",
       "4  Metropolitan Statistical Area  ...          NaN      Moderate         High   \n",
       "\n",
       "  c5_SE_WL_met r_SE_WL_nat  r_SE_WL_stt  r_SE_WL_met  z_SE_WL_nat   \n",
       "0          NaN        42.0         60.0          NaN    -0.185168  \\\n",
       "1          NaN        38.0         53.0          NaN    -0.241784   \n",
       "2          NaN        31.0         43.0          NaN    -0.329964   \n",
       "3          NaN        43.0         67.0          NaN    -0.179954   \n",
       "4          NaN        45.0         68.0          NaN    -0.150777   \n",
       "\n",
       "   z_SE_WL_stt  z_SE_WL_met  \n",
       "0     0.046977          NaN  \n",
       "1    -0.050226          NaN  \n",
       "2    -0.160692          NaN  \n",
       "3     0.145209          NaN  \n",
       "4     0.187417          NaN  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This shows the first few rows of the df and all the columns (hence, \"head\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geoid10\n",
      "year\n",
      "state_fips\n",
      "state_usps\n",
      "state_name\n",
      "county_fips\n",
      "county_name\n",
      "metro_fips\n",
      "metro_name\n",
      "metro_type\n",
      "in100\n",
      "primary_ruca\n",
      "c5_ED_EC_nat\n",
      "c5_ED_EC_stt\n",
      "c5_ED_EC_met\n",
      "r_ED_EC_nat\n",
      "r_ED_EC_stt\n",
      "r_ED_EC_met\n",
      "z_ED_EC_nat\n",
      "z_ED_EC_stt\n",
      "z_ED_EC_met\n",
      "c5_ED_EL_nat\n",
      "c5_ED_EL_stt\n",
      "c5_ED_EL_met\n",
      "r_ED_EL_nat\n",
      "r_ED_EL_stt\n",
      "r_ED_EL_met\n",
      "z_ED_EL_nat\n",
      "z_ED_EL_stt\n",
      "z_ED_EL_met\n",
      "c5_ED_ER_nat\n",
      "c5_ED_ER_stt\n",
      "c5_ED_ER_met\n",
      "r_ED_ER_nat\n",
      "r_ED_ER_stt\n",
      "r_ED_ER_met\n",
      "z_ED_ER_nat\n",
      "z_ED_ER_stt\n",
      "z_ED_ER_met\n",
      "c5_ED_SP_nat\n",
      "c5_ED_SP_stt\n",
      "c5_ED_SP_met\n",
      "r_ED_SP_nat\n",
      "r_ED_SP_stt\n",
      "r_ED_SP_met\n",
      "z_ED_SP_nat\n",
      "z_ED_SP_stt\n",
      "z_ED_SP_met\n",
      "c5_HE_EP_nat\n",
      "c5_HE_EP_stt\n",
      "c5_HE_EP_met\n",
      "r_HE_EP_nat\n",
      "r_HE_EP_stt\n",
      "r_HE_EP_met\n",
      "z_HE_EP_nat\n",
      "z_HE_EP_stt\n",
      "z_HE_EP_met\n",
      "c5_HE_HR_nat\n",
      "c5_HE_HR_stt\n",
      "c5_HE_HR_met\n",
      "r_HE_HR_nat\n",
      "r_HE_HR_stt\n",
      "r_HE_HR_met\n",
      "z_HE_HR_nat\n",
      "z_HE_HR_stt\n",
      "z_HE_HR_met\n",
      "c5_HE_SE_nat\n",
      "c5_HE_SE_stt\n",
      "c5_HE_SE_met\n",
      "r_HE_SE_nat\n",
      "r_HE_SE_stt\n",
      "r_HE_SE_met\n",
      "z_HE_SE_nat\n",
      "z_HE_SE_stt\n",
      "z_HE_SE_met\n",
      "c5_HE_HE_nat\n",
      "c5_HE_HE_stt\n",
      "c5_HE_HE_met\n",
      "r_HE_HE_nat\n",
      "r_HE_HE_stt\n",
      "r_HE_HE_met\n",
      "z_HE_HE_nat\n",
      "z_HE_HE_stt\n",
      "z_HE_HE_met\n",
      "c5_SE_EI_nat\n",
      "c5_SE_EI_stt\n",
      "c5_SE_EI_met\n",
      "r_SE_EI_nat\n",
      "r_SE_EI_stt\n",
      "r_SE_EI_met\n",
      "z_SE_EI_nat\n",
      "z_SE_EI_stt\n",
      "z_SE_EI_met\n",
      "c5_SE_EO_nat\n",
      "c5_SE_EO_stt\n",
      "c5_SE_EO_met\n",
      "r_SE_EO_nat\n",
      "r_SE_EO_stt\n",
      "r_SE_EO_met\n",
      "z_SE_EO_nat\n",
      "z_SE_EO_stt\n",
      "z_SE_EO_met\n",
      "c5_SE_ER_nat\n",
      "c5_SE_ER_stt\n",
      "c5_SE_ER_met\n",
      "r_SE_ER_nat\n",
      "r_SE_ER_stt\n",
      "r_SE_ER_met\n",
      "z_SE_ER_nat\n",
      "z_SE_ER_stt\n",
      "z_SE_ER_met\n",
      "c5_SE_HQ_nat\n",
      "c5_SE_HQ_stt\n",
      "c5_SE_HQ_met\n",
      "r_SE_HQ_nat\n",
      "r_SE_HQ_stt\n",
      "r_SE_HQ_met\n",
      "z_SE_HQ_nat\n",
      "z_SE_HQ_stt\n",
      "z_SE_HQ_met\n",
      "c5_SE_SR_nat\n",
      "c5_SE_SR_stt\n",
      "c5_SE_SR_met\n",
      "r_SE_SR_nat\n",
      "r_SE_SR_stt\n",
      "r_SE_SR_met\n",
      "z_SE_SR_nat\n",
      "z_SE_SR_stt\n",
      "z_SE_SR_met\n",
      "c5_SE_WL_nat\n",
      "c5_SE_WL_stt\n",
      "c5_SE_WL_met\n",
      "r_SE_WL_nat\n",
      "r_SE_WL_stt\n",
      "r_SE_WL_met\n",
      "z_SE_WL_nat\n",
      "z_SE_WL_stt\n",
      "z_SE_WL_met\n"
     ]
    }
   ],
   "source": [
    "for x in df.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 subdomains in this dataset: \n",
    "\n",
    "- Education\n",
    "- Health\n",
    "- Socioeconomic factors\n",
    "\n",
    "There are also overall features. For my preliminary models, I will ignore it for now.\n",
    "\n",
    "I choose socioeconomic to be the first subdomain I explore.\n",
    "\n",
    "I noticed that the pattern in features is:\n",
    "\n",
    "- Child Opportunity Levels\n",
    "- Child Opportunity Scores\n",
    "- z-scores \n",
    "\n",
    "These are:\n",
    "\n",
    "- nationally normed\n",
    "- state normed\n",
    "- metro normed\n",
    "\n",
    "Also, I realized we have all these features (x), but what is our (y)? What are we trying to predict? We want to find the most indicative features that predict the chances of someone missing an appointment. The problem is, we don't have labels for supervised learning of whether someone in the COI missed their appt or not.\n",
    "\n",
    "To keep things simple, I will just throw all the socioeconomic features into my first model.\n",
    "\n",
    "- ! Future: reduce number of features for each subdomain... investigate which matter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-1661fa4f2018>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_feats.fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training info obtained.\n",
      "Testing info obtained.\n",
      "Training model...........\n",
      "Model Trained!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1661fa4f2018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Trained!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Make a prediction with the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction Made!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[1;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[1;32m    581\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \"\"\"\n\u001b[0;32m--> 871\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import scikit-learn, the library with all the machine learning models\n",
    "# Import kNN\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# First, gather only the features that we want to feed into the model\n",
    "# features = [\n",
    "#     \"c5_SE_EI_nat\", \"c5_SE_EI_stt\", \"c5_SE_EI_met\",\n",
    "#     \"r_SE_EI_nat\", \"r_SE_EI_stt\", \"r_SE_EI_met\",\n",
    "#     \"z_SE_EI_nat\", \"z_SE_EI_stt\", \"z_SE_EI_met\",\n",
    "#     \"c5_SE_EO_nat\", \"c5_SE_EO_stt\", \"c5_SE_EO_met\",\n",
    "#     \"r_SE_EO_nat\", \"r_SE_EO_stt\", \"r_SE_EO_met\",\n",
    "#     \"z_SE_EO_nat\", \"z_SE_EO_stt\", \"z_SE_EO_met\",\n",
    "#     \"c5_SE_ER_nat\", \"c5_SE_ER_stt\", \"c5_SE_ER_met\",\n",
    "#     \"r_SE_ER_nat\", \"r_SE_ER_stt\", \"r_SE_ER_met\",\n",
    "#     \"z_SE_ER_nat\", \"z_SE_ER_stt\", \"z_SE_ER_met\",\n",
    "#     \"c5_SE_HQ_nat\", \"c5_SE_HQ_stt\", \"c5_SE_HQ_met\",\n",
    "#     \"r_SE_HQ_nat\", \"r_SE_HQ_stt\", \"r_SE_HQ_met\",\n",
    "#     \"z_SE_HQ_nat\", \"z_SE_HQ_stt\", \"z_SE_HQ_met\",\n",
    "#     \"c5_SE_SR_nat\", \"c5_SE_SR_stt\", \"c5_SE_SR_met\",\n",
    "#     \"r_SE_SR_nat\", \"r_SE_SR_stt\", \"r_SE_SR_met\",\n",
    "#     \"z_SE_SR_nat\", \"z_SE_SR_stt\", \"z_SE_SR_met\",\n",
    "#     \"c5_SE_WL_nat\", \"c5_SE_WL_stt\", \"c5_SE_WL_met\",\n",
    "#     \"r_SE_WL_nat\", \"r_SE_WL_stt\", \"r_SE_WL_met\",\n",
    "#     \"z_SE_WL_nat\", \"z_SE_WL_stt\", \"z_SE_WL_met\"\n",
    "# ]\n",
    "\n",
    "features = [\n",
    "    \"r_SE_EI_nat\", \"r_SE_EI_stt\", \"r_SE_EI_met\",\n",
    "    \"z_SE_EI_nat\", \"z_SE_EI_stt\", \"z_SE_EI_met\",\n",
    "    \"r_SE_EO_nat\", \"r_SE_EO_stt\", \"r_SE_EO_met\",\n",
    "    \"z_SE_EO_nat\", \"z_SE_EO_stt\", \"z_SE_EO_met\",\n",
    "    \"r_SE_ER_nat\", \"r_SE_ER_stt\", \"r_SE_ER_met\",\n",
    "    \"z_SE_ER_nat\", \"z_SE_ER_stt\", \"z_SE_ER_met\",\n",
    "    \"r_SE_HQ_nat\", \"r_SE_HQ_stt\", \"r_SE_HQ_met\",\n",
    "    \"z_SE_HQ_nat\", \"z_SE_HQ_stt\", \"z_SE_HQ_met\",\n",
    "    \"r_SE_SR_nat\", \"r_SE_SR_stt\", \"r_SE_SR_met\",\n",
    "    \"z_SE_SR_nat\", \"z_SE_SR_stt\", \"z_SE_SR_met\",\n",
    "    \"r_SE_WL_nat\", \"r_SE_WL_stt\", \"r_SE_WL_met\",\n",
    "    \"z_SE_WL_nat\", \"z_SE_WL_stt\", \"z_SE_WL_met\"\n",
    "]\n",
    "\n",
    "# 725996 rows, 54 columns\n",
    "df_feats = df[features]\n",
    "df_feats.fillna(0, inplace=True)\n",
    "\n",
    "# print(df_feats)\n",
    "\n",
    "# For now, we replace nan with 0\n",
    "# print(df_feats.isna().sum().sum())\n",
    "\n",
    "\n",
    "# If we had the response variable\n",
    "# df_y = ['Missed Appointments']\n",
    "# Note: this is a random filler response variable I chose, does not have any meaning to it\n",
    "df_y = df['in100']\n",
    "df_y.fillna(0, inplace=True)\n",
    "\n",
    "# Skip pre-processing for now (normalization)\n",
    "\n",
    "# Roughly 80-20 Train Test Split:\n",
    "# Train has 580796 rows\n",
    "# Test has 145200 rows\n",
    "df_train_x = df_feats[:580796]\n",
    "df_train_y = df_y[:580796]\n",
    "\n",
    "print(\"Training info obtained.\")\n",
    "\n",
    "df_test_x = df_feats[580796:]\n",
    "df_test_y = df_y[580796:]\n",
    "print(\"Testing info obtained.\")\n",
    "\n",
    "\n",
    "# Train the kNN model:\n",
    "print(\"Training model...........\")\n",
    "clf = KNeighborsClassifier().fit(df_train_x,df_train_y)\n",
    "print(\"Model Trained!\")\n",
    "# Make a prediction with the trained model\n",
    "prediction = clf.predict(df_test_x)\n",
    "print(\"Prediction Made!\")\n",
    "\n",
    "\n",
    "# Compare prediction to the actual ground truth (df_test_y)\n",
    "# Joins the column storing our trained model's prediction to the column with the ground truth\n",
    "evaluation_df = pd.DataFrame(prediction, df_test_y)\n",
    "identical_rows = evaluation_df.apply(lambda row: row.nunique() == 1, axis=1)\n",
    "num_identical_rows = identical_rows.sum()\n",
    "\n",
    "# Print percentage of correctly guessed rows\n",
    "print(\"Accuracy Score:\")\n",
    "print((num_identical_rows * 100)//len(evaluation_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
