{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load NOTEEVENTS \n",
    "\n",
    "Notes to self\n",
    "- first 60 rows in column A is junk\n",
    "- After those rows, data is categorized as follows (according to https://mimic.mit.edu/docs/iii/tables/noteevents/)\n",
    "\n",
    "Table: \n",
    "- ROW_ID\tINT\n",
    "- SUBJECT_ID\tINT\n",
    "- HADM_ID\tINT\n",
    "- CHARTDATE\tTIMESTAMP(0)\n",
    "- CHARTTIME\tTIMESTAMP(0)\n",
    "- STORETIME\tTIMESTAMP(0)\n",
    "- CATEGORY\tVARCHAR(50)\n",
    "- DESCRIPTION\tVARCHAR(300)\n",
    "- CGID\tINT\n",
    "- ISERROR\tCHAR(1)\n",
    "- TEXT\tTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noah1\\AppData\\Local\\Temp\\ipykernel_18836\\2500189943.py:3: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  noteevents = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
      "0  716996       55118  102445.0  2110-11-21  2110-11-21 06:24:00   \n",
      "1  717001       55118  102445.0  2110-11-21  2110-11-21 11:44:00   \n",
      "2  717067       53244  184401.0  2107-12-16  2107-12-16 22:01:00   \n",
      "3  717068       57615  127312.0  2158-01-27  2158-01-27 22:17:00   \n",
      "4  717069       57615  127312.0  2158-01-27  2158-01-27 22:17:00   \n",
      "\n",
      "             STORETIME    CATEGORY            DESCRIPTION     CGID  ISERROR  \\\n",
      "0  2110-11-21 11:12:56  Physician        Intensivist Note  21070.0      NaN   \n",
      "1  2110-11-21 11:44:59     Nursing  Nursing Transfer Note  17600.0      NaN   \n",
      "2  2107-12-16 22:01:59     Nursing  Nursing Progress Note  14891.0      NaN   \n",
      "3  2158-01-27 22:18:01     General           Generic Note  16037.0      NaN   \n",
      "4  2158-01-27 22:46:29     General           Generic Note  16037.0      NaN   \n",
      "\n",
      "                                                TEXT  \n",
      "0  CVICU\\n   HPI:\\n   HD5   POD 2-CABGx4(LIMA-LAD...  \n",
      "1  D #2 from cx4.\\n   Hyperglycemia\\n   Assessmen...  \n",
      "2  Labile bp with brisk huo,low filling pressures...  \n",
      "3  TITLE: Pt was made CMO at previous shift,all f...  \n",
      "4  TITLE: Pt was made CMO at previous shift,all f...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "noteevents = pd.read_csv(\n",
    "    'NOTEEVENTS.csv', \n",
    "    skiprows=60  # Skip the first 60 rows\n",
    ")\n",
    "\n",
    "# Assign column names to the dataframe\n",
    "noteevents.columns = [\n",
    "    'ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'CHARTTIME', \n",
    "    'STORETIME', 'CATEGORY', 'DESCRIPTION', 'CGID', 'ISERROR', 'TEXT'\n",
    "]\n",
    "print(noteevents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter relevant note categories and save to Relevant_NOTEEVENTS.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SUBJECT_ID   HADM_ID    CATEGORY  \\\n",
      "0       55118  102445.0  Physician    \n",
      "1       55118  102445.0     Nursing   \n",
      "2       53244  184401.0     Nursing   \n",
      "3       57615  127312.0     General   \n",
      "4       57615  127312.0     General   \n",
      "\n",
      "                                                TEXT  \n",
      "0  CVICU\\n   HPI:\\n   HD5   POD 2-CABGx4(LIMA-LAD...  \n",
      "1  D #2 from cx4.\\n   Hyperglycemia\\n   Assessmen...  \n",
      "2  Labile bp with brisk huo,low filling pressures...  \n",
      "3  TITLE: Pt was made CMO at previous shift,all f...  \n",
      "4  TITLE: Pt was made CMO at previous shift,all f...  \n"
     ]
    }
   ],
   "source": [
    "# Filter for relevant note categories (determine if we should include other categories like general or physician)\n",
    "\n",
    "#relevant_notes = noteevents[noteevents['CATEGORY'].isin(['Social Work', 'Nursing', 'General', 'Physician', 'Nursing/other', 'Nutrition'])]\n",
    "\n",
    "# test with all categories (see if it affects 'None' label distribution)\n",
    "relevant_notes = noteevents\n",
    "\n",
    "# Select only required columns\n",
    "relevant_notes = relevant_notes[['SUBJECT_ID', 'HADM_ID', 'CATEGORY', 'TEXT']]\n",
    "\n",
    "# Display the first few rows of the filtered notes\n",
    "print(relevant_notes.head())\n",
    "\n",
    "relevant_notes.to_csv('Relevant_NOTEEVENTS.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keyword-based approach for labeling cleaned text (Will have to consider other methods, will likely get a lot of entries labled `NONE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple keyword rules\n",
    "def enhanced_keyword_label(text):\n",
    "    text = text.lower()\n",
    "    if any(word in text for word in [\"homeless\", \"shelter\", \"evicted\", \"no stable housing\"]):\n",
    "        return \"Housing Instability\"\n",
    "    elif any(word in text for word in [\"transport\", \"distance\", \"commute\", \"travel issues\"]):\n",
    "        return \"Transportation Issues\"\n",
    "    elif any(word in text for word in [\"afford\", \"financial\", \"money\", \"costly\", \"expensive\"]):\n",
    "        return \"Financial Difficulty\"\n",
    "    elif any(word in text for word in [\"family\", \"support\", \"caretaker\", \"guardian\"]):\n",
    "        return \"Social Support\"\n",
    "    elif any(word in text for word in [\"food\", \"nutrition\", \"hunger\", \"malnutrition\"]):\n",
    "        return \"Food Insecurity\"\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "# apply keyword-based labeling\n",
    "relevant_notes['LABEL'] = relevant_notes['TEXT'].apply(enhanced_keyword_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect Prelabled data (ensure it makes sense/captures relevant categories)\n",
    "\n",
    "Result: Abdundant amount of `None` labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL\n",
      "Social Support           238907\n",
      "Food Insecurity           16387\n",
      "Transportation Issues      6021\n",
      "Housing Instability         317\n",
      "Financial Difficulty        238\n",
      "Name: count, dtype: int64\n",
      "                                                TEXT           LABEL\n",
      "0  D #2 from cx4.\\n   Hyperglycemia\\n   Assessmen...             NaN\n",
      "1  Labile bp with brisk huo,low filling pressures...             NaN\n",
      "2  TITLE: Pt was made CMO at previous shift,all f...  Social Support\n",
      "3  TITLE: Pt was made CMO at previous shift,all f...  Social Support\n",
      "4  Delirium / confusion\\n   Assessment:\\n   Minim...             NaN\n",
      "5  [**Age over 90 **] year old female found down ...             NaN\n",
      "6  48M with recently diagnosed Large B-Cell Lymph...             NaN\n",
      "7  [**Age over 90 **] year old female found down ...             NaN\n",
      "8  55 yr old with severe PVD, CAD with EF 20%, ES...  Social Support\n",
      "9                                           TITLE:\\n             NaN\n",
      "Number of 'None' labels: 572724\n"
     ]
    }
   ],
   "source": [
    "# Load prelabeled data\n",
    "prelabeled_notes = pd.read_csv('prelabeled_notes.csv')\n",
    "\n",
    "# Check the label distribution\n",
    "print(prelabeled_notes['LABEL'].value_counts()) \n",
    "\n",
    "# Inspect a few examples\n",
    "print(prelabeled_notes[['TEXT', 'LABEL']].head(10))\n",
    "\n",
    "# Replace NaN values in the LABEL column with 'None'\n",
    "prelabeled_notes['LABEL'] = prelabeled_notes['LABEL'].fillna('None')\n",
    "\n",
    "# Get the count of 'None' labels\n",
    "none_count = prelabeled_notes['LABEL'].value_counts().get('None', 0)\n",
    "print(f\"Number of 'None' labels: {none_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: The dataset is heavily imbalanced, with `None` being the majority label. This means ClinicalBERT might overfit to `None`, which happens when the model learns to always predict the majority label because it sees it so often. As a result, it wonâ€™t properly learn to recognize the less common labels like 'Housing Instability' or 'Financial Difficulty'.\n",
    "\n",
    "Solutions:\n",
    "\n",
    "- Balance the dataset: \n",
    "    - Downsampling `None`: reduce the number of 'None' labels so they match the size of smaller labels (ex: if there are 100,000 `None` and 5,000 `housing instability`, randomly pick 5,000 None samples to keep) \n",
    "    \n",
    "    - Oversampling Minority labels: Duplicate the notes for smaller labels (e.g., `Housing instability`) to make them more frequent in the dataset\n",
    "\n",
    "- use weighted approach: \n",
    "    - Instead of changing the dataset, assign more weight to mistakes on minority labels during training\n",
    "\n",
    "- Fine-Tuning with ClinicalBERT:\n",
    "    Because we have a large number of `None` labels, fine-tuning ClinicalBERT can help capture implicit patterns (information not stated directly but understood from context of text) in the data and balance the label distribution, improving classification of minority SDOH categories like `Housing Instability` and `Transportation Issues`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for Fine-Tuning ClinicalBERT:\n",
    "\n",
    "- Load the dataset of pre-labeled clinical notes and encode text labels (e.g., \"Housing Instability\") into numerical values.\n",
    "\n",
    "- Split the dataset into training and validation sets, ensuring that the label proportions are balanced in both sets (stratification).\n",
    "\n",
    "- Save the splits to separate files for use during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 667675\n",
      "Validation set size: 166919\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load prelabeled notes\n",
    "data = pd.read_csv('prelabeled_notes.csv')\n",
    "\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['LABEL_NUM'] = encoder.fit_transform(data['LABEL'])  # Converts text labels to numbers\n",
    "label_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, stratify=data['LABEL_NUM'], random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(val_data))\n",
    "\n",
    "# Save training and validation sets to separate files\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "val_data.to_csv('val_data.csv', index=False)\n",
    "\n",
    "print(\"Training and validation splits saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
